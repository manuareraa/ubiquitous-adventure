{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74d66b9",
   "metadata": {},
   "source": [
    "### Model Adaptation & Behavior Controlling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35446362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and execute if not done in README.ipynb\n",
    "# !pip install -r default_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17479e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory if not in tutorial\n",
    "# import os\n",
    "# os.chdir(\"./tutorial\")\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['HF_TOKEN'] = \"\"\n",
    "# os.environ['HF_HOME']=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f7fdc",
   "metadata": {},
   "source": [
    "### Quality of Model Response\n",
    "\n",
    "You yourself can run the following cells and see how quality of response being affected by SFT and GRPO.\n",
    "\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b15d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Base model:\n",
    "!python -m trainer --mode inference --inference_output simple_inference.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c9721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sft-trained model:\n",
    "!python -m trainer --mode inference --output_dir checkpoints/demo/sft --inference_output sft_inference.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grpo-trained model:\n",
    "!python -m trainer --mode inference --output_dir checkpoints/demo/grpo --inference_output grpo_inference.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b57f9",
   "metadata": {},
   "source": [
    "\n",
    "#### SFT (Supervised Fine-tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68681cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /jupyter-tutorial/hf_models/Llama-3.2-1B-Instruct\n",
    "!python -m trainer \\\n",
    "    --training_type sft \\\n",
    "    --mode train \\\n",
    "    --model_name \"/jupyter-tutorial/hf_models/Llama-3.2-1B-Instruct\" \\\n",
    "    --output_dir \"checkpoints/sft\" \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --lora_r 32 \\\n",
    "    --lora_alpha 64 \\\n",
    "    --disable_wandb # remove this or comment out for wandb logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b5fa8",
   "metadata": {},
   "source": [
    "#### RL (GRPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRPO: /jupyter-tutorial/hf_models/Llama-3.2-1B-Instruct\n",
    "!python -m trainer \\\n",
    "    --training_type grpo \\\n",
    "    --mode train \\\n",
    "    --model_name \"/jupyter-tutorial/hf_models/Llama-3.2-1B-Instruct\" \\\n",
    "    --output_dir \"checkpoints/grpo\" \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 2 \\\n",
    "    --lora_r 16 \\\n",
    "    --lora_alpha 32 \\\n",
    "    --vllm_gpu_memory_utilization 0.7 \\\n",
    "    --disable_wandb # remove this or comment out for wandb logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f99808",
   "metadata": {},
   "source": [
    "**For more such use cases, go through `__main__` block of [trainer.py](trainer.py)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb90b4",
   "metadata": {},
   "source": [
    "If SFT ckpt is used for GRPO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6748d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to bring your own code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747fe63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945b5b67",
   "metadata": {},
   "source": [
    "### Prompt Tuning\n",
    "\n",
    "In this section we'll see how you efficiently communicate with your model (*make your thoughts visible*) to obtain what you desired. Just like the following image üòú."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38669e2a",
   "metadata": {},
   "source": [
    "<img src=\"../assets/prompt.jpg\">\n",
    "\n",
    "Pic Credits: [Edurado Ordax](https://www.linkedin.com/in/eordax/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6ed03",
   "metadata": {},
   "source": [
    "*The following prompt-tuning can be tested out at [question_agent.py](../agents/question_agent.py) `__main__` code block.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A demonstration of how tuning-prompt improves the model output.\n",
    "\n",
    "# Basic prompt:\n",
    "sys_prompt1 = \"You are an examiner tasked with creating extremely difficult multiple-choice questions\"\n",
    "\n",
    "output1 = \"\"\"\n",
    "        {\n",
    "            \"question\": \"Identify the next number: 23, 43, 73, 113, ?\",\n",
    "            \"choices\": [\n",
    "                \"A) 163\",\n",
    "                \"B) 173\",\n",
    "                \"C) 157\",\n",
    "                \"D) 167\"\n",
    "            ],\n",
    "            \"answer\": \"A) 163\",\n",
    "            \"explanation\": \"The differences between terms increase by 10 each time: 43-23=20, 73-43=30, 113-73=40, so next difference is 50. 113+50=163, which is also a prime.\"\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# After we tune the prompt as per our requirement (i.e., conveying model our intentions) we get following:\n",
    "sys_prompt2 = \"\"\"\n",
    "    You are an **expert-level examiner** with deep expertise in designing **highly challenging and conceptually rigorous multiple-choice questions (MCQs)** for the **Quantitative Aptitude and Analytical Reasoning** sections of top-tier competitive exams.\n",
    "    Think step by step to generate the question and solve the same, but only output the final answer. Do not show your thinking process.\n",
    "    **Please DO NOT reveal the solution steps or any intermediate reasoning.**\n",
    "\"\"\"\n",
    "\n",
    "# Output: \n",
    "output2 = \"\"\"\n",
    "        {\n",
    "            \"question\": \"What is the next term in the series: 2, 5, 10, 15, 90, 97, ?, 2339\",\n",
    "            \"choices\": [\n",
    "                \"A) 582\",\n",
    "                \"B) 1164\",\n",
    "                \"C) 1746\",\n",
    "                \"D) 2328\"\n",
    "            ],\n",
    "            \"answer\": \"D) 2328\",\n",
    "            \"explanation\": \"The pattern alternates between adding the next prime number and multiplying by the next factorial: 2 + 3 = 5, 5 x 2! = 10, 10 + 5 = 15, 15 x 3! = 90, 90 + 7 = 97, 97 x 4! = 2328, 2328 + 11 = 2339. So the missing term is 97 x 24 = 2328.\"\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# NOTE: Here the `sys_prompt` denotes the system-prompt which sets the context, tone, and boundaries for the AI's actions, shaping its overall conduct throughout the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4643dfa",
   "metadata": {},
   "source": [
    "##### Examples of Prompt-tuning:\n",
    "1. CoT\n",
    "2. Few-Shot (In-context) prompting\n",
    "3. Self-consistency decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e8730f",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">Tips and Tricks</span>:\n",
    "\n",
    "*   SFT/GRPO/Prompt-finetuning (also Distillation) for improved response from agents. This\n",
    "    *   Ensure format correctness\n",
    "    *   Ensure question-choices-answer correctness\n",
    "    *   Improve question difficulty\n",
    "    *   Improve answer scoring\n",
    "    *   Try improving reasoning ability\n",
    "    *   Create a good training dataset (with reasoning traces maybe)\n",
    "*   *Datasets if required can be sourced through internet or generated using Frontier models.*\n",
    "*   <span style=\"color: green\">Try</span> dividing the aspects for improvements among yourselves as much as possible - *Team that works together, wins together*üèÜ.\n",
    "*   Finally, <span style=\"color : teal\">*Like catches win matches - similarly tips wins patches*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f89cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
